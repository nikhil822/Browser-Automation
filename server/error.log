{"cause":{"address":"127.0.0.1","code":"ECONNREFUSED","errno":-61,"port":11434,"syscall":"connect"},"level":"error","message":"Failed to process command: fetch failed","stack":"TypeError: fetch failed\n    at node:internal/deps/undici/undici:13502:13\n    at processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at createOllamaStream (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/community/dist/utils/ollama.cjs:12:22)\n    at createOllamaChatStream (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/community/dist/utils/ollama.cjs:61:5)\n    at ChatOllama._streamResponseChunks (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/community/dist/chat_models/ollama.cjs:412:30)\n    at ChatOllama._call (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/community/dist/chat_models/ollama.cjs:520:26)\n    at ChatOllama._generate (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:588:22)\n    at async Promise.allSettled (index 0)\n    at ChatOllama._generateUncached (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:227:29)\n    at ChatOllama.invoke (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:65:24)","timestamp":"2025-04-06T04:56:27.239Z"}
{"cause":{"address":"127.0.0.1","code":"ECONNREFUSED","errno":-61,"port":11434,"syscall":"connect"},"level":"error","message":"Command execution failed: fetch failed","stack":"TypeError: fetch failed\n    at node:internal/deps/undici/undici:13502:13\n    at processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at createOllamaStream (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/community/dist/utils/ollama.cjs:12:22)\n    at createOllamaChatStream (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/community/dist/utils/ollama.cjs:61:5)\n    at ChatOllama._streamResponseChunks (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/community/dist/chat_models/ollama.cjs:412:30)\n    at ChatOllama._call (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/community/dist/chat_models/ollama.cjs:520:26)\n    at ChatOllama._generate (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:588:22)\n    at async Promise.allSettled (index 0)\n    at ChatOllama._generateUncached (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:227:29)\n    at ChatOllama.invoke (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:65:24)","timestamp":"2025-04-06T04:56:27.239Z"}
{"error":"model \"mistral\" not found, try pulling it first","level":"error","message":"Failed to process command: model \"mistral\" not found, try pulling it first","name":"ResponseError","stack":"ResponseError: model \"mistral\" not found, try pulling it first\n    at checkOk (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:77:9)\n    at processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at post (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:141:3)\n    at Ollama.processStreamableRequest (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:252:25)\n    at ChatOllama._streamResponseChunks (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/ollama/dist/chat_models.cjs:759:24)\n    at ChatOllama._generate (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/ollama/dist/chat_models.cjs:692:26)\n    at async Promise.allSettled (index 0)\n    at ChatOllama._generateUncached (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:227:29)\n    at ChatOllama.invoke (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:65:24)\n    at processCommand (/Users/nikhil_13/Documents/Browser-automation/server/src/core/CommandProcessor.ts:63:26)","status_code":404,"timestamp":"2025-04-06T14:46:00.664Z"}
{"error":"model \"mistral\" not found, try pulling it first","level":"error","message":"Command execution failed: model \"mistral\" not found, try pulling it first","name":"ResponseError","stack":"ResponseError: model \"mistral\" not found, try pulling it first\n    at checkOk (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:77:9)\n    at processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at post (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:141:3)\n    at Ollama.processStreamableRequest (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:252:25)\n    at ChatOllama._streamResponseChunks (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/ollama/dist/chat_models.cjs:759:24)\n    at ChatOllama._generate (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/ollama/dist/chat_models.cjs:692:26)\n    at async Promise.allSettled (index 0)\n    at ChatOllama._generateUncached (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:227:29)\n    at ChatOllama.invoke (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:65:24)\n    at processCommand (/Users/nikhil_13/Documents/Browser-automation/server/src/core/CommandProcessor.ts:63:26)","status_code":404,"timestamp":"2025-04-06T14:46:00.665Z"}
{"error":"model \"mistral\" not found, try pulling it first","level":"error","message":"Failed to process command: model \"mistral\" not found, try pulling it first","name":"ResponseError","stack":"ResponseError: model \"mistral\" not found, try pulling it first\n    at checkOk (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:77:9)\n    at processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at post (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:141:3)\n    at Ollama.processStreamableRequest (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:252:25)\n    at ChatOllama._streamResponseChunks (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/ollama/dist/chat_models.cjs:759:24)\n    at ChatOllama._generate (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/ollama/dist/chat_models.cjs:692:26)\n    at async Promise.allSettled (index 0)\n    at ChatOllama._generateUncached (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:227:29)\n    at ChatOllama.invoke (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:65:24)\n    at processCommand (/Users/nikhil_13/Documents/Browser-automation/server/src/core/CommandProcessor.ts:63:26)","status_code":404,"timestamp":"2025-04-06T14:46:06.994Z"}
{"error":"model \"mistral\" not found, try pulling it first","level":"error","message":"Command execution failed: model \"mistral\" not found, try pulling it first","name":"ResponseError","stack":"ResponseError: model \"mistral\" not found, try pulling it first\n    at checkOk (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:77:9)\n    at processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at post (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:141:3)\n    at Ollama.processStreamableRequest (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/ollama/dist/browser.cjs:252:25)\n    at ChatOllama._streamResponseChunks (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/ollama/dist/chat_models.cjs:759:24)\n    at ChatOllama._generate (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/ollama/dist/chat_models.cjs:692:26)\n    at async Promise.allSettled (index 0)\n    at ChatOllama._generateUncached (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:227:29)\n    at ChatOllama.invoke (/Users/nikhil_13/Documents/Browser-automation/server/node_modules/@langchain/core/dist/language_models/chat_models.cjs:65:24)\n    at processCommand (/Users/nikhil_13/Documents/Browser-automation/server/src/core/CommandProcessor.ts:63:26)","status_code":404,"timestamp":"2025-04-06T14:46:06.994Z"}
